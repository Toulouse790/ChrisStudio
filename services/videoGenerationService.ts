/**
 * Video Generation Service
 * Generates complete videos using AI (script, images, voiceover)
 * PRODUCTION VERSION - Uses real APIs
 * 
 * Supports:
 * - Shotstack (cloud, fast, high quality) - if configured
 * - Browser Canvas (fallback, slower)
 */

import { GoogleGenAI } from '@google/genai';
import { CalendarItem, Channel } from '../types';
import { generateSceneMedia } from './mediaService';
import { generateVoiceover, isElevenLabsAvailable } from './audioService';
import { assembleVideo, generateThumbnail as createThumbnail } from './videoAssemblyService';
import { isShotstackAvailable, generateVideoWithShotstack, uploadAudioForShotstack } from './shotstackService';

// Get API key
const getApiKey = (): string => {
  const key = import.meta.env.VITE_API_KEY;
  if (!key) {
    throw new Error('VITE_API_KEY not configured');
  }
  return key;
};

// Download video from URL to Blob
const downloadVideoBlob = async (url: string): Promise<Blob> => {
  const response = await fetch(url);
  if (!response.ok) {
    throw new Error(`Failed to download video: ${response.status}`);
  }
  return response.blob();
};

export interface GeneratedVideo {
  id: string;
  contentItem: CalendarItem;
  script: string;
  scenes: GeneratedScene[];
  voiceoverBlob?: Blob;
  thumbnailBlob?: Blob;
  videoBlob?: Blob;
  voiceoverUrl?: string;
  thumbnailUrl?: string;
  finalVideoUrl?: string;
  status: 'pending' | 'generating-script' | 'generating-images' | 'generating-audio' | 'assembling' | 'ready' | 'error';
  progress: number;
  error?: string;
}

export interface GeneratedScene {
  id: number;
  text: string;
  imagePrompt: string;
  imageUrl?: string;
  videoUrl?: string;
  duration: number; // seconds
}

export interface GenerationProgress {
  stage: string;
  progress: number;
  message: string;
}

type ProgressCallback = (progress: GenerationProgress) => void;

/**
 * Generate a complete video from a content item
 */
export const generateVideo = async (
  contentItem: CalendarItem,
  channel: Channel,
  onProgress?: ProgressCallback
): Promise<GeneratedVideo> => {
  const video: GeneratedVideo = {
    id: `video_${Date.now()}`,
    contentItem,
    script: '',
    scenes: [],
    status: 'pending',
    progress: 0
  };

  try {
    // Step 1: Generate Script
    onProgress?.({ stage: 'script', progress: 5, message: 'G√©n√©ration du script...' });
    video.status = 'generating-script';
    video.script = await generateScript(contentItem, channel);
    video.progress = 15;

    // Step 2: Parse script into scenes
    onProgress?.({ stage: 'scenes', progress: 18, message: 'D√©coupage en sc√®nes...' });
    video.scenes = parseScriptToScenes(video.script);
    
    // Log dur√©e estim√©e
    const totalDuration = video.scenes.reduce((acc, s) => acc + s.duration, 0);
    const minutes = Math.floor(totalDuration / 60);
    const seconds = totalDuration % 60;
    console.log(`üìä Dur√©e vid√©o estim√©e: ${minutes}:${seconds.toString().padStart(2, '0')} (${video.scenes.length} sc√®nes)`);
    onProgress?.({ stage: 'scenes', progress: 19, message: `${video.scenes.length} sc√®nes (~${minutes}:${seconds.toString().padStart(2, '0')})` });
    video.progress = 20;

    // Step 3: Generate image prompts for each scene
    onProgress?.({ stage: 'prompts', progress: 22, message: 'Cr√©ation des prompts visuels...' });
    video.scenes = await generateImagePrompts(video.scenes, channel);
    video.progress = 25;

    // Step 4: Fetch real images/videos from Pexels
    onProgress?.({ stage: 'images', progress: 28, message: 'Recherche des m√©dias sur Pexels...' });
    video.status = 'generating-images';
    video.scenes = await generateSceneImages(video.scenes, (p, m) => {
      onProgress?.({ stage: 'images', progress: 28 + (p * 0.22), message: m });
    });
    video.progress = 50;

    // Step 5: Generate voiceover - TEXTE COMPLET POUR ELEVENLABS
    onProgress?.({ stage: 'audio', progress: 52, message: `G√©n√©ration voix off (${isElevenLabsAvailable() ? 'ElevenLabs' : 'Navigateur'})...` });
    video.status = 'generating-audio';
    
    // Concat√©ner TOUT le texte des sc√®nes pour la narration compl√®te
    const voiceText = video.scenes.map(s => s.text).join('\n\n');
    const wordCount = voiceText.split(/\s+/).length;
    const charCount = voiceText.length;
    console.log(`üé§ Texte pour ElevenLabs: ${wordCount} mots, ${charCount} caract√®res`);
    console.log(`üìñ Aper√ßu du texte:\n${voiceText.substring(0, 500)}...`);
    
    video.voiceoverBlob = await generateVoiceover(voiceText, (p, m) => {
      onProgress?.({ stage: 'audio', progress: 52 + (p * 0.15), message: m });
    });
    video.voiceoverUrl = URL.createObjectURL(video.voiceoverBlob);
    video.progress = 67;

    // Step 6: Generate thumbnail
    onProgress?.({ stage: 'thumbnail', progress: 68, message: 'Cr√©ation de la miniature...' });
    const thumbnailImageUrl = video.scenes[0]?.imageUrl || '';
    video.thumbnailBlob = await createThumbnail(thumbnailImageUrl, contentItem.title);
    video.thumbnailUrl = URL.createObjectURL(video.thumbnailBlob);
    video.progress = 70;

    // Step 7: Assemble final video
    video.status = 'assembling';
    
    // Try Shotstack for fast cloud rendering, but fallback to browser if audio upload fails
    let useShotstack = isShotstackAvailable();
    let audioUrl: string | null = null;
    
    if (useShotstack && video.voiceoverBlob) {
      onProgress?.({ stage: 'assembly', progress: 72, message: 'Tentative upload audio pour Shotstack...' });
      audioUrl = await uploadAudioForShotstack(video.voiceoverBlob);
      
      if (!audioUrl) {
        console.warn('‚ö†Ô∏è Audio upload failed - using browser assembly to preserve audio');
        onProgress?.({ stage: 'assembly', progress: 73, message: '‚ö†Ô∏è Upload audio √©chou√©, utilisation assemblage navigateur...' });
        useShotstack = false; // Force browser assembly to keep audio
      }
    }
    
    if (useShotstack) {
      onProgress?.({ stage: 'assembly', progress: 74, message: '‚ö° Rendu cloud Shotstack (ultra-rapide)...' });
      
      try {
        // Prepare media for Shotstack
        const shotstackScenes = video.scenes.map(s => ({
          imageUrl: s.imageUrl || '',
          videoUrl: s.videoUrl || '', // Passer les vid√©os Pexels √† Shotstack
          text: s.text,
          duration: s.duration
        }));
        
        // Generate video with Shotstack
        const result = await generateVideoWithShotstack(
          shotstackScenes,
          audioUrl || undefined,
          (progress, message) => {
            onProgress?.({ 
              stage: 'assembly', 
              progress: 74 + (progress * 0.20), 
              message: `Shotstack: ${message}` 
            });
          }
        );
        
        if ('error' in result) {
          throw new Error(result.error);
        }
        
        onProgress?.({ stage: 'assembly', progress: 95, message: 'T√©l√©chargement de la vid√©o HD...' });
        video.videoBlob = await downloadVideoBlob(result.videoUrl);
        video.finalVideoUrl = URL.createObjectURL(video.videoBlob);
        video.progress = 97;
        
      } catch (shotstackError) {
        console.warn('Shotstack failed, falling back to browser assembly:', shotstackError);
        onProgress?.({ stage: 'assembly', progress: 72, message: 'Fallback: assemblage navigateur...' });
        
        // Fallback to browser assembly
        const videoScenes = video.scenes.map(s => ({
          imageUrl: s.imageUrl || '',
          videoUrl: s.videoUrl,
          text: s.text,
          duration: s.duration
        }));
        video.videoBlob = await assembleVideo(videoScenes, video.voiceoverBlob, {}, (p, m) => {
          onProgress?.({ stage: 'assembly', progress: 72 + (p * 0.25), message: m });
        });
        video.finalVideoUrl = URL.createObjectURL(video.videoBlob);
        video.progress = 97;
      }
    } else {
      // Browser-based assembly (slower but works without API key)
      onProgress?.({ stage: 'assembly', progress: 72, message: 'Assemblage navigateur (ajoutez SHOTSTACK pour acc√©l√©rer)...' });
      
      const videoScenes = video.scenes.map(s => ({
        imageUrl: s.imageUrl || '',
        videoUrl: s.videoUrl,
        text: s.text,
        duration: s.duration
      }));
      video.videoBlob = await assembleVideo(videoScenes, video.voiceoverBlob, {}, (p, m) => {
        onProgress?.({ stage: 'assembly', progress: 72 + (p * 0.25), message: m });
      });
      video.finalVideoUrl = URL.createObjectURL(video.videoBlob);
      video.progress = 97;
    }

    // Step 8: Complete
    onProgress?.({ stage: 'complete', progress: 100, message: 'Vid√©o pr√™te √† publier !' });
    video.status = 'ready';
    video.progress = 100;

    return video;

  } catch (error) {
    video.status = 'error';
    video.error = error instanceof Error ? error.message : 'Erreur inconnue';
    console.error('Video generation error:', error);
    throw error;
  }
};

/**
 * Generate a detailed script for the video - VERSION D√âFINITIVE
 * Adapt√© aux cha√Ænes: Dossiers Classifi√©s, Et Si..., L'Odyss√©e Humaine
 */
async function generateScript(item: CalendarItem, channel: Channel): Promise<string> {
  const ai = new GoogleGenAI({ apiKey: getApiKey() });
  
  // D√©terminer le style selon la cha√Æne
  const channelStyle = getChannelStyle(channel.name, channel.theme);
  
  const prompt = `Tu es un SC√âNARISTE DE DOCUMENTAIRES CIN√âMATOGRAPHIQUES pour YouTube.
Tu cr√©es des scripts pour des vid√©os style "documentaire 3D" √† forte r√©tention.

CHA√éNE: ${channel.name}
TH√àME: ${channel.theme}
TITRE: ${item.title}
SUJET: ${item.description}

${channelStyle.instructions}

=== R√àGLES D'OR ===

**1. LA R√àGLE DES 4 SECONDES:**
Tu n'as que 4 secondes pour captiver. La premi√®re phrase d√©cide TOUT.
INTERDIT: "Bonjour √† tous", "Bienvenue", "Aujourd'hui on va parler de..."
Le spectateur doit √™tre HAPP√â imm√©diatement.

**2. NARRATION CIN√âMATOGRAPHIQUE:**
- √âcris comme un FILM, pas comme un article
- Cr√©e des IMAGES MENTALES puissantes
- Utilise le PR√âSENT pour l'immersion: "Il est 3h du matin. Les rues sont d√©sertes..."
- Fais RESSENTIR les √©motions, pas juste les d√©crire

**3. TECHNIQUE QPC (Quoi-Pourquoi-Comment):**
- QUOI: Le sujet captivant
- POURQUOI: L'enjeu, ce qu'on risque de manquer
- COMMENT: La promesse de ce qu'on va d√©couvrir

**4. ARC NARRATIF EN 6 ACTES:**
Acte 1: ACCROCHE ‚Üí Captiver en 4 secondes
Acte 2: CONTEXTE ‚Üí Poser le d√©cor, cr√©er l'atmosph√®re
Acte 3: R√âV√âLATION 1 ‚Üí Premi√®re info surprenante
Acte 4: TENSION ‚Üí Monter les enjeux
Acte 5: CLIMAX ‚Üí La r√©v√©lation ultime
Acte 6: CONCLUSION ‚Üí Message m√©morable

=== STRUCTURE DU SCRIPT ===

**PARAGRAPHE 1 - ACCROCHE CIN√âMATOGRAPHIQUE (80 mots):**
${channelStyle.hookStyle}
Phrase 1-2: Accroche IMPOSSIBLE √† ignorer (statistique choc, question br√ªlante, sc√®ne immersive)
Phrase 3-4: Contexte rapide - POURQUOI c'est fascinant
Phrase 5-6: Promesse - Ce que le spectateur va d√©couvrir
Le spectateur doit penser: "Il FAUT que je voie √ßa."

**PARAGRAPHE 2 - IMMERSION DANS LE CONTEXTE (100 mots):**
${channelStyle.contextStyle}
Cr√©e une ATMOSPH√àRE. Fais voyager le spectateur.
Utilise des d√©tails SENSORIELS: sons, images, ambiances.
Pose les bases de l'histoire avec des faits captivants.
Termine par une transition vers la premi√®re r√©v√©lation.

**PARAGRAPHE 3 - PREMI√àRE R√âV√âLATION (100 mots):**
${channelStyle.revelationStyle}
Livre une information SURPRENANTE.
"Ce que peu de gens savent..."
Utilise des exemples CONCRETS et visuels.
Cr√©e un micro-cliffhanger: "Mais ce n'√©tait que le d√©but..."

**PARAGRAPHE 4 - MONT√âE DRAMATIQUE (100 mots):**
${channelStyle.tensionStyle}
Intensifie la tension. "Et c'est l√† que tout bascule..."
Deuxi√®me r√©v√©lation, encore plus forte.
Connexions inattendues, retournements.
Le spectateur sent qu'il approche de LA v√©rit√©.

**PARAGRAPHE 5 - CLIMAX / R√âV√âLATION ULTIME (100 mots):**
${channelStyle.climaxStyle}
Le moment "MIND-BLOWN".
LA r√©v√©lation qui change tout.
Le spectateur a sa prise de conscience.
Information la plus pr√©cieuse de la vid√©o.

**PARAGRAPHE 6 - CONCLUSION M√âMORABLE (80 mots):**
${channelStyle.conclusionStyle}
Synth√®se percutante en 2-3 phrases.
Message qui reste en t√™te.
Question ouverte pour les commentaires.
Derni√®re phrase = celle qu'on retient.

=== STYLE D'√âCRITURE CIN√âMATOGRAPHIQUE ===
- Phrases COURTES et PERCUTANTES (max 15 mots)
- Rythme DYNAMIQUE: alterne punch et respiration
- Utilise le PR√âSENT pour l'immersion
- Descriptions VISUELLES: le spectateur doit VOIR la sc√®ne
- Ponctuation EXPRESSIVE: ... pour le suspense, ! pour l'impact
- Transitions FLUIDES: "Mais attendez...", "Et c'est l√† que..."
- JAMAIS de phrases plates ou acad√©miques

=== TECHNIQUE AUDIO ===
- Ce texte sera lu par ElevenLabs (voix off dramatique)
- Phrases faciles √† lire √† voix haute
- Pauses naturelles entre les id√©es (. ou ...)
- Rythme qui permet la respiration
- Mots forts en fin de phrase pour l'impact

=== IMPORTANT ===
- S√©pare CHAQUE paragraphe par UNE LIGNE VIDE
- Total: ~560 mots (~4 minutes de narration)
- Le spectateur doit √™tre CAPTIV√â du d√©but √† la fin
- Style UNIQUE, pas g√©n√©rique - comme les grandes cha√Ænes documentaires

G√©n√®re maintenant le script CIN√âMATOGRAPHIQUE en fran√ßais:

`;

  const response = await ai.models.generateContent({
    model: 'gemini-2.0-flash',
    contents: prompt
  });

  const script = response.text || '';
  
  // Log word count for debug
  const wordCount = script.split(/\s+/).length;
  console.log(`üìù Script g√©n√©r√©: ${wordCount} mots`);
  
  return script;
}

/**
 * Get channel-specific style instructions
 */
function getChannelStyle(channelName: string, theme: string): {
  instructions: string;
  hookStyle: string;
  contextStyle: string;
  revelationStyle: string;
  tensionStyle: string;
  climaxStyle: string;
  conclusionStyle: string;
} {
  const lowerName = channelName.toLowerCase();
  const lowerTheme = theme.toLowerCase();
  
  // DOSSIERS CLASSIFI√âS - Myst√®res, enqu√™tes, secrets
  if (lowerName.includes('dossier') || lowerName.includes('classif') || 
      lowerTheme.includes('myst√®re') || lowerTheme.includes('secret') || lowerTheme.includes('enqu√™te')) {
    return {
      instructions: `=== STYLE "DOSSIERS CLASSIFI√âS" ===
Ton: MYST√âRIEUX, INTRIGANT, SUSPENSE
Ambiance: Enqu√™te, secrets r√©v√©l√©s, v√©rit√©s cach√©es
Vocabulaire: "classifi√©", "r√©v√©l√©", "dissimul√©", "la v√©rit√© sur...", "ce qu'on ne vous dit pas"
√âmotion: Curiosit√©, tension, r√©v√©lation`,
      hookStyle: `Style ENQU√äTE/MYST√àRE:
"Cette histoire a √©t√© classifi√©e pendant 50 ans. Aujourd'hui, les archives s'ouvrent enfin..."
"Ce que vous allez d√©couvrir a √©t√© cach√© au public pendant des d√©cennies..."
"Il y a des v√©rit√©s qu'on pr√©f√®re garder dans l'ombre. Celle-ci en fait partie..."`,
      contextStyle: `Pose l'atmosph√®re d'une ENQU√äTE:
D√©tails sur le contexte historique, les acteurs impliqu√©s.
Cr√©e un sentiment de myst√®re et d'intrigue.
"Dans les coulisses du pouvoir...", "Derri√®re les portes closes..."`,
      revelationStyle: `R√©v√®le comme un ENQU√äTEUR:
"Les documents d√©classifi√©s r√©v√®lent que..."
"Ce que les archives montrent est troublant..."
Indices, preuves, t√©moignages qui s'accumulent.`,
      tensionStyle: `Monte la tension comme un THRILLER:
"Mais l'affaire prend un tournant inattendu..."
"C'est l√† que les choses deviennent vraiment √©tranges..."
Retournements, zones d'ombre, questions sans r√©ponse.`,
      climaxStyle: `La R√âV√âLATION finale:
"La v√©rit√©, c'est que..."
"Ce que personne n'avait compris jusqu'ici..."
Le voile se l√®ve sur le myst√®re.`,
      conclusionStyle: `Conclusion MYST√âRIEUSE:
"Cette affaire soul√®ve une question troublante..."
"Et vous, que pensez-vous vraiment de cette histoire ?"
Laisse planer un dernier doute ou une r√©flexion.`
    };
  }
  
  // ET SI... - Sc√©narios hypoth√©tiques, uchronies
  if (lowerName.includes('et si') || lowerTheme.includes('hypoth√®') || 
      lowerTheme.includes('scenario') || lowerTheme.includes('uchronie')) {
    return {
      instructions: `=== STYLE "ET SI..." ===
Ton: SP√âCULATIF, FASCINANT, VERTIGINEUX
Ambiance: Exploration de possibilit√©s, r√©alit√©s alternatives
Vocabulaire: "imaginez", "et si", "dans ce sc√©nario", "les cons√©quences seraient..."
√âmotion: √âmerveillement, vertige, fascination`,
      hookStyle: `Style HYPOTH√âTIQUE/VERTIGINEUX:
"Et si tout ce que vous pensiez savoir √©tait faux ?"
"Imaginez un monde o√π [sc√©nario]. Les cons√©quences seraient vertigineuses..."
"Cette simple question va bouleverser votre vision de [sujet]..."`,
      contextStyle: `Pose le SC√âNARIO HYPOTH√âTIQUE:
Explique les conditions de d√©part.
"Pour comprendre, il faut d'abord imaginer que..."
Cr√©e un cadre mental fascinant.`,
      revelationStyle: `Explore les CONS√âQUENCES:
"La premi√®re cons√©quence serait stup√©fiante..."
"Ce que la science nous dit, c'est que..."
Faits scientifiques + extrapolations logiques.`,
      tensionStyle: `AMPLIFIE le sc√©nario:
"Mais ce n'est que le d√©but. Les effets en cascade seraient..."
"Et si on pousse le raisonnement encore plus loin..."
Chaque r√©v√©lation en am√®ne une plus grande.`,
      climaxStyle: `La R√âALISATION vertigineuse:
"Et c'est l√† qu'on comprend l'ampleur de..."
"La conclusion est √† la fois fascinante et terrifiante..."
Le "mind-blown" moment.`,
      conclusionStyle: `Conclusion OUVERTE:
"Ce sc√©nario nous force √† reconsid√©rer..."
"Et vous, comment r√©agiriez-vous si demain... ?"
Invite √† la r√©flexion et au d√©bat.`
    };
  }
  
  // L'ODYSS√âE HUMAINE - Histoire, civilisations, explorations
  if (lowerName.includes('odyss√©e') || lowerName.includes('humaine') || 
      lowerTheme.includes('histoire') || lowerTheme.includes('civilis') || lowerTheme.includes('explor')) {
    return {
      instructions: `=== STYLE "L'ODYSS√âE HUMAINE" ===
Ton: √âPIQUE, INSPIRANT, GRANDIOSE
Ambiance: Voyage √† travers le temps, grandeur de l'humanit√©
Vocabulaire: "nos anc√™tres", "l'humanit√©", "√† travers les √¢ges", "l'√©pop√©e de..."
√âmotion: √âmerveillement, fiert√©, connexion avec le pass√©`,
      hookStyle: `Style √âPIQUE/HISTORIQUE:
"Il y a [X] ans, l'humanit√© a accompli l'impossible..."
"Cette d√©couverte a chang√© le cours de l'histoire humaine √† jamais..."
"Au c≈ìur de [lieu], une civilisation a b√¢ti quelque chose d'extraordinaire..."`,
      contextStyle: `TRANSPORTE dans l'√©poque:
Descriptions immersives du lieu et de l'√©poque.
"Imaginez-vous en [ann√©e], dans [lieu]..."
D√©tails sensoriels: sons, odeurs, ambiances.`,
      revelationStyle: `R√©v√®le la GRANDEUR:
"Ce que les arch√©ologues ont d√©couvert d√©passe l'imagination..."
"Nos anc√™tres avaient compris quelque chose que nous avons oubli√©..."
Faits historiques fascinants.`,
      tensionStyle: `Monte vers l'APOG√âE:
"Mais le plus extraordinaire restait √† venir..."
"C'est √† ce moment que [civilisation/personnage] a accompli..."
Progression vers le climax historique.`,
      climaxStyle: `Le moment L√âGENDAIRE:
"Et c'est ainsi que l'humanit√© a prouv√©..."
"Ce qui s'est pass√© ce jour-l√† reste grav√© dans l'histoire..."
L'accomplissement ultime.`,
      conclusionStyle: `Conclusion INSPIRANTE:
"Cette histoire nous rappelle que l'humanit√©..."
"Et vous, quel h√©ritage souhaitez-vous laisser ?"
Message universel et intemporel.`
    };
  }
  
  // STYLE PAR D√âFAUT - Documentaire g√©n√©rique
  return {
    instructions: `=== STYLE DOCUMENTAIRE CIN√âMATOGRAPHIQUE ===
Ton: CAPTIVANT, INFORMATIF, ENGAGEANT
Ambiance: D√©couverte, exploration, r√©v√©lation
Vocabulaire: vari√©, pr√©cis, √©vocateur
√âmotion: Curiosit√©, fascination, compr√©hension`,
    hookStyle: `Style ACCROCHE UNIVERSELLE:
Statistique choc, question br√ªlante, ou sc√®ne immersive.
"Ce que vous allez d√©couvrir va changer votre perspective..."`,
    contextStyle: `Pose le D√âCOR avec immersion:
Contexte clair, d√©tails captivants.
Cr√©e une atmosph√®re engageante.`,
    revelationStyle: `SURPRENDS avec des faits:
Informations inattendues, exemples concrets.
"Ce que peu de gens savent..."`,
    tensionStyle: `INTENSIFIE progressivement:
Mont√©e en puissance des r√©v√©lations.
Connexions surprenantes.`,
    climaxStyle: `Le POINT CULMINANT:
La r√©v√©lation la plus importante.
Le moment de prise de conscience.`,
    conclusionStyle: `Conclusion M√âMORABLE:
Synth√®se percutante.
Question ouverte pour l'engagement.`
  };
}

/**
 * Parse script into individual scenes - NARRATION D√âTAILL√âE
 */
function parseScriptToScenes(script: string): GeneratedScene[] {
  // Split by paragraphs or scene indicators
  const paragraphs = script.split(/\n\n+/).filter(p => p.trim().length > 30);
  
  // 6 sc√®nes avec narration compl√®te (~560 mots = ~4 min)
  // Dur√©e moyenne de lecture vocale: ~150 mots/minute = 2.5 mots/seconde
  return paragraphs.slice(0, 6).map((text, index) => {
    const wordCount = text.split(/\s+/).length;
    // Dur√©e bas√©e sur la lecture vocale: 150 mots/min = 2.5 mots/sec
    // Minimum 10 secondes par sc√®ne pour les paragraphes d√©taill√©s
    const estimatedDuration = Math.max(10, Math.ceil(wordCount / 2.5));
    
    console.log(`üìñ Sc√®ne ${index + 1}: ${wordCount} mots ‚Üí ${estimatedDuration}s`);
    
    return {
      id: index + 1,
      text: text.trim(),
      imagePrompt: '',
      duration: estimatedDuration
    };
  });
}

/**
 * Generate search keywords for each scene (optimized for Pexels video search)
 */
async function generateImagePrompts(scenes: GeneratedScene[], channel: Channel): Promise<GeneratedScene[]> {
  const ai = new GoogleGenAI({ apiKey: getApiKey() });
  
  const sceneTexts = scenes.map((s, i) => `Sc√®ne ${i + 1}: ${s.text.substring(0, 300)}`).join('\n\n');
  
  const prompt = `Tu es expert en recherche de stock footage sur Pexels. Pour chaque sc√®ne, g√©n√®re des TERMES DE RECHERCHE PEXELS en anglais.

CHA√éNE: "${channel.name}"
TH√àME: ${channel.theme}

SC√àNES:
${sceneTexts}

R√àGLES CRITIQUES:
1. G√©n√®re 1-2 termes CONCRETS par sc√®ne (pas de mots-cl√©s s√©par√©s)
2. Les termes doivent correspondre √† ce qui EXISTE SUR PEXELS
3. EXEMPLES QUI FONCTIONNENT:
   - "ocean waves drone" (pour la mer)
   - "ancient temple ruins" (pour l'histoire)
   - "night city lights" (pour ville)
   - "forest fog mystery" (pour for√™t)
   - "storm clouds dramatic" (pour temp√™te)
   - "space stars galaxy" (pour espace)
   - "fire flames burning" (pour feu)
   - "crowd people walking" (pour foule)
   - "desert sand dunes" (pour d√©sert)
   - "mountain snow peaks" (pour montagne)
   - "laboratory science" (pour science)
   - "war military soldiers" (pour guerre)

4. √âVITE ABSOLUMENT:
   - Mots abstraits: mystery, secret, revelation, amazing, incredible
   - Noms propres: Triangle des Bermudes, Atlantis, etc.
   - Concepts: th√©orie, explication, d√©couverte

R√©ponds UNIQUEMENT avec ce JSON (rien d'autre):
[
  {"scene": 1, "keywords": "ocean waves storm"},
  {"scene": 2, "keywords": "ancient ruins temple"}
]`;

  const response = await ai.models.generateContent({
    model: 'gemini-2.0-flash',
    contents: prompt
  });

  try {
    const text = response.text || '[]';
    const jsonMatch = text.match(/\[[\s\S]*\]/);
    if (jsonMatch) {
      const prompts = JSON.parse(jsonMatch[0]);
      return scenes.map((scene, i) => ({
        ...scene,
        imagePrompt: prompts[i]?.keywords || prompts[i]?.prompt || `documentary footage`
      }));
    }
  } catch (e) {
    console.warn('Failed to parse search keywords, using scene text');
  }

  // Fallback: utiliser le texte de la sc√®ne directement
  return scenes.map(scene => ({
    ...scene,
    imagePrompt: scene.text.substring(0, 100)
  }));
}

/**
 * Generate images for scenes using Pexels API
 */
async function generateSceneImages(
  scenes: GeneratedScene[], 
  onProgress?: (progress: number, message: string) => void
): Promise<GeneratedScene[]> {
  const mediaResults = await generateSceneMedia(scenes, onProgress);
  
  return scenes.map((scene, index) => {
    const media = mediaResults.find(m => m.sceneId === scene.id) || mediaResults[index];
    return {
      ...scene,
      imageUrl: media?.imageUrl || '',
      videoUrl: media?.videoUrl || ''
    };
  });
}

/**
 * Get video generation status summary
 */
export const getGenerationStatusText = (status: GeneratedVideo['status']): string => {
  const statusMap: Record<GeneratedVideo['status'], string> = {
    'pending': 'En attente',
    'generating-script': 'G√©n√©ration du script...',
    'generating-images': 'Recherche m√©dias Pexels...',
    'generating-audio': 'Synth√®se vocale...',
    'assembling': 'Assemblage vid√©o...',
    'ready': 'Pr√™t √† publier',
    'error': 'Erreur'
  };
  return statusMap[status] || status;
};

/**
 * Export video data for external processing (if needed)
 */
export const exportVideoData = (video: GeneratedVideo): object => {
  return {
    title: video.contentItem.title,
    description: video.contentItem.description,
    script: video.script,
    scenes: video.scenes.map(s => ({
      text: s.text,
      imagePrompt: s.imagePrompt,
      imageUrl: s.imageUrl,
      videoUrl: s.videoUrl,
      duration: s.duration
    })),
    hasVideo: !!video.videoBlob,
    hasThumbnail: !!video.thumbnailBlob,
    hasVoiceover: !!video.voiceoverBlob
  };
};

/**
 * Download the generated video
 */
export const downloadGeneratedVideo = (video: GeneratedVideo): void => {
  if (!video.videoBlob) {
    throw new Error('No video available to download');
  }
  
  const url = URL.createObjectURL(video.videoBlob);
  const a = document.createElement('a');
  a.href = url;
  a.download = `${video.contentItem.title.replace(/[^a-zA-Z0-9]/g, '_')}.webm`;
  document.body.appendChild(a);
  a.click();
  document.body.removeChild(a);
  URL.revokeObjectURL(url);
};

/**
 * Get the video file for YouTube upload
 */
export const getVideoFile = (video: GeneratedVideo): File | null => {
  if (!video.videoBlob) return null;
  
  return new File(
    [video.videoBlob], 
    `${video.contentItem.title.replace(/[^a-zA-Z0-9]/g, '_')}.webm`,
    { type: 'video/webm' }
  );
};

/**
 * Get the thumbnail file for YouTube upload
 */
export const getThumbnailFile = (video: GeneratedVideo): File | null => {
  if (!video.thumbnailBlob) return null;
  
  return new File(
    [video.thumbnailBlob],
    `thumbnail_${video.id}.jpg`,
    { type: 'image/jpeg' }
  );
};
